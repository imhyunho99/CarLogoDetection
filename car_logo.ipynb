{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "zMlowMVCaWaX",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:01:48.247073Z",
     "start_time": "2025-03-10T11:01:40.613854Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torchvision\n",
    "import pretrainedmodels\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def seed_everything(SEED=41):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YzWO32z582j4",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:01:49.922888Z",
     "start_time": "2025-03-10T11:01:49.918204Z"
    }
   },
   "source": [
    "class_list =[\n",
    "    ['acura',173250000],\n",
    "    ['alfaromeo',82500000],\n",
    "    ['buick',59400000],\n",
    "    ['cadillac',110000000],\n",
    "    ['dodge',88000000],\n",
    "    ['fiat',33000000],\n",
    "    ['opel',44000000]\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T11:01:50.684149Z",
     "start_time": "2025-03-10T11:01:50.680150Z"
    }
   },
   "cell_type": "code",
   "source": "print('test')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1sMA9hfHaWat",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:01:51.659329Z",
     "start_time": "2025-03-10T11:01:51.652958Z"
    }
   },
   "source": [
    "dataset_path = \"F:\\프로젝트\\CarLogoDetection\\data\"\n",
    "train_val_split_ratio = 0.8\n",
    "learning_rate = 0.0001\n",
    "num_epoch = 100\n",
    "batch_size = 8\n",
    "class_num = 7\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
    "])\n",
    "dataset = ImageFolder(root=dataset_path, transform=trans)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\nahyu\\AppData\\Local\\Temp\\ipykernel_12868\\617455154.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  dataset_path = \"F:\\프로젝트\\CarLogoDetection\\data\"\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A6Oder8gNtm0",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:01:54.584524Z",
     "start_time": "2025-03-10T11:01:52.768170Z"
    }
   },
   "source": [
    "train_data, test_data = train_test_split(dataset, test_size = 0.2,random_state = 42)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QecZaPqin2oX",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:02:45.478368Z",
     "start_time": "2025-03-10T11:02:45.473555Z"
    }
   },
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "teat_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xxd7n2XAgX60",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:02:46.390396Z",
     "start_time": "2025-03-10T11:02:46.386417Z"
    }
   },
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7607,
     "status": "ok",
     "timestamp": 1692017516625,
     "user": {
      "displayName": "나현호",
      "userId": "13994604800831256900"
     },
     "user_tz": -540
    },
    "id": "wMJGS8NZaWa-",
    "outputId": "79669401-9389-4ec5-c7c7-ffcd4f2ca7d5",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:02:47.857617Z",
     "start_time": "2025-03-10T11:02:47.292841Z"
    }
   },
   "source": [
    "#model\n",
    "\n",
    "# the resnet34 model\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet34, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__['resnet34'](pretrained=None)\n",
    "\n",
    "        # change the classification layer\n",
    "        self.l0 = nn.Linear(512, class_num)\n",
    "        self.dropout = nn.Dropout2d(0.6)\n",
    "    def forward(self, x):\n",
    "        # get the batch size only, ignore (c, h, w)\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        x = self.dropout(x)\n",
    "        l0 = self.l0(x)\n",
    "        return l0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNet34(pretrained=True).to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahyu\\anaconda3\\envs\\CarLogoDetection\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahyu\\anaconda3\\envs\\CarLogoDetection\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SddvTNcQaWbF",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:02:48.714202Z",
     "start_time": "2025-03-10T11:02:48.709234Z"
    }
   },
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93519,
     "status": "ok",
     "timestamp": 1692017620034,
     "user": {
      "displayName": "나현호",
      "userId": "13994604800831256900"
     },
     "user_tz": -540
    },
    "id": "t3mgt5RYaWbI",
    "outputId": "752e8eec-fe4d-4c5f-c0a6-09250e595d79",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:24:43.908571Z",
     "start_time": "2025-03-10T11:02:49.291394Z"
    }
   },
   "source": [
    "#train\n",
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_= label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(loss)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahyu\\anaconda3\\envs\\CarLogoDetection\\Lib\\site-packages\\torch\\nn\\functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1686392603168,
     "user": {
      "displayName": "나현호",
      "userId": "13994604800831256900"
     },
     "user_tz": -540
    },
    "id": "Pzrp77gWN2Jy",
    "outputId": "23dd932d-5ab9-4d37-d1de-e9a9401eeb2b",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:24:45.504603Z",
     "start_time": "2025-03-10T11:24:44.025306Z"
    }
   },
   "source": [
    "#test\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for image,label in test_loader:\n",
    "      x = image.to(device)\n",
    "      y_= label.to(device)\n",
    "      output = model.forward(x)\n",
    "      _,output_index = torch.max(output,1)\n",
    "      total += label.size(0)\n",
    "      correct += (output_index == y_).sum().float()\n",
    "\n",
    "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 100.0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "665a4Lqf--ba",
    "ExecuteTime": {
     "end_time": "2025-03-10T11:27:38.053864Z",
     "start_time": "2025-03-10T11:27:36.974563Z"
    }
   },
   "source": [
    "torch.save(model.state_dict(), 'model')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "error",
     "timestamp": 1686392603778,
     "user": {
      "displayName": "나현호",
      "userId": "13994604800831256900"
     },
     "user_tz": -540
    },
    "id": "NyvJDJJZD54h",
    "outputId": "5e7ffd52-eef2-4b81-c8b1-20a103126c7b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-783fe6130e5e>\u001B[0m in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m# 새로운 이미지 로드 및 전처리\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mimage_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/content/tester.png\"\u001B[0m  \u001B[0;31m# 사용할 이미지 파일 업로드 후\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPIL\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"RGB\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0minput_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrans\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   2973\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2974\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2975\u001B[0;31m         \u001B[0mfp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2976\u001B[0m         \u001B[0mexclusive_fp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2977\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/tester.png'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import PIL\n",
    "# 모델 불러오기\n",
    "model = ResNet34(pretrained=True).to(device)\n",
    "model.load_state_dict(torch.load(\"model\"))  #학습한 모델 사용\n",
    "\n",
    "# 새로운 이미지 로드 및 전처리\n",
    "image_path = \"/content/tester.png\"  # 사용할 이미지 파일 업로드 후\n",
    "image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "input_image = trans(image).unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_image = input_image.to('cuda')\n",
    "\n",
    "# 모델 입력 및 예측\n",
    "output = model(input_image)\n",
    "\n",
    "# 예측 결과 확인\n",
    "predicted_label = torch.argmax(output)\n",
    "\n",
    "print(\"예측된 라벨:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ME7r5BrdKs4D"
   },
   "outputs": [],
   "source": [
    "predicted_label.cpu()\n",
    "k = predicted_label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5mzXc02HzDr"
   },
   "outputs": [],
   "source": [
    "com = class_list[k]\n",
    "\n",
    "print(\"이 차량 정보: \" ,com[0],\"사의 차량으로\", \"최대\",com[1],\"원 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a63EYEfrLUke"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1Vfh7uPPY1HBpSYqkhEeUWUKjjq01E3jE",
     "timestamp": 1685889762145
    },
    {
     "file_id": "1Qt8T2kjXRGjrt20n_dcWCm7u8iqHTQA5",
     "timestamp": 1684730133470
    },
    {
     "file_id": "1PmZv3VTTxTokzUwWTJMinTcLcWESrCbW",
     "timestamp": 1684719040603
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
